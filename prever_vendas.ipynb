{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "17fcc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0cdf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_livros_vendidos = pd.read_csv(\"../data/livros_vendidos.csv\").drop(columns=\"preco\")\n",
    "\n",
    "df_livros = df_livros_vendidos[[\"livro\", \"genero\", \"autor\", \"editora\"]]\n",
    "df_vendas_totais = df_livros_vendidos.groupby(\"autor\")[\"vendas\"].sum().reset_index()\n",
    "df_vendas_por_livraria = df_livros_vendidos.groupby([\"autor\", \"livraria\"])[\"vendas\"].sum().reset_index()\n",
    "\n",
    "# print(f\"df_livros_vendidos:    \", df_livros_vendidos.columns.to_list())\n",
    "# print(f\"df_livros:             \", df_livros.columns.to_list())\n",
    "# print(f\"df_vendas_totais:      \", df_vendas_totais.columns.to_list())\n",
    "# print(f\"df_vendas_por_livraria:\", df_vendas_por_livraria.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "93d94ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_livros_vendidos:     ['livro', 'genero', 'autor', 'editora', 'livraria', 'vendas']\n",
    "# df_livros:              ['livro', 'genero', 'autor', 'editora']\n",
    "# df_vendas_totais:       ['autor', 'vendas']\n",
    "# df_vendas_por_livraria: ['autor', 'livraria', 'vendas']\n",
    "\n",
    "# ===========================================\n",
    "# 2. Exemplo: unindo as tabelas\n",
    "# ===========================================\n",
    "df_base = df_vendas_por_livraria.merge(df_livros, on=\"autor\", how=\"left\")\n",
    "df_base = df_base.merge(df_vendas_totais, on=\"autor\", how=\"left\", suffixes=(\"\", \"_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "82801d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 3. Cria√ß√£o de features\n",
    "# ===========================================\n",
    "# Propor√ß√£o de vendas do autor por livraria\n",
    "df_base[\"prop_vendas_livraria\"] = df_base[\"vendas\"] / df_base[\"vendas_total\"]\n",
    "\n",
    "# Popularidade da editora e genero\n",
    "popularidade_autor = df_base.groupby(\"autor\")[\"vendas_total\"].mean().rename(\"pop_autor\")\n",
    "popularidade_livraria = df_base.groupby(\"livraria\")[\"vendas_total\"].mean().rename(\"pop_livraria\")\n",
    "popularidade_editora = df_base.groupby(\"editora\")[\"vendas_total\"].mean().rename(\"pop_editora\")\n",
    "popularidade_tema = df_base.groupby(\"genero\")[\"vendas_total\"].mean().rename(\"pop_genero\")\n",
    "\n",
    "df_base = df_base.merge(popularidade_autor, on=\"autor\", how=\"left\")\n",
    "df_base = df_base.merge(popularidade_livraria, on=\"livraria\", how=\"left\")\n",
    "df_base = df_base.merge(popularidade_editora, on=\"editora\", how=\"left\")\n",
    "df_base = df_base.merge(popularidade_tema, on=\"genero\", how=\"left\")\n",
    "# ===========================================\n",
    "# 4. Sele√ß√£o de vari√°veis\n",
    "# ===========================================\n",
    "features = [\"autor\", \"livraria\", \"genero\", \"editora\", \"pop_autor\", \"pop_livraria\", \"pop_editora\", \"pop_genero\"]\n",
    "target = \"vendas\"\n",
    "\n",
    "X = df_base[features]\n",
    "y = df_base[target]\n",
    "# ===========================================\n",
    "# 5. Pr√©-processamento (OneHotEncoder para vari√°veis categ√≥ricas)\n",
    "# ===========================================\n",
    "categorical_features = [\"autor\", \"livraria\", \"genero\", \"editora\"]\n",
    "numeric_features = [\"pop_autor\", \"pop_livraria\", \"pop_editora\", \"pop_genero\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "    ]\n",
    ")\n",
    "# ===========================================\n",
    "# 6. Modelo (XGBoost)\n",
    "# ===========================================\n",
    "model = XGBRegressor(n_estimators=300, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "\n",
    "# Pipeline completo\n",
    "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "# ===========================================\n",
    "# 7. Treinamento e avalia√ß√£o\n",
    "# ===========================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# - MAE (erro m√©dio absoluto):\n",
    "#       m√©dia do erro em unidades de vendas (ex: ‚Äúem m√©dia o modelo erra por 50 c√≥pias‚Äù).\n",
    "# - RMSE (erro quadr√°tico m√©dio):\n",
    "#       penaliza mais grandes erros ‚Äî √∫til para identificar instabilidade.\n",
    "# - R¬≤ (coeficiente de determina√ß√£o): varia de 0 a 1.\n",
    "#           0.8 ‚Üí modelo muito bom.\n",
    "#       0.5~0.8 ‚Üí razo√°vel.\n",
    "#       < 0.5 ‚Üí precisa de ajuste (talvez falta de vari√°veis).\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R¬≤: {r2:.2f}\")\n",
    "# ===========================================\n",
    "# 8. Previs√£o para um novo livro\n",
    "# ===========================================\n",
    "aut = \"Jo√£o Silva\"\n",
    "liv = \"Livraria Fnac\"\n",
    "gen = \"Romance\"\n",
    "edi = \"Editora Record\"\n",
    "novo_livro = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"autor\": aut,\n",
    "            \"livraria\": liv,\n",
    "            \"genero\": gen,\n",
    "            \"editora\": edi,\n",
    "            \"pop_autor\": df_base[df_base[\"autor\"] == aut][\"pop_autor\"].mean(),\n",
    "            \"pop_livraria\": df_base[df_base[\"livraria\"] == liv][\"pop_livraria\"].mean(),\n",
    "            \"pop_editora\": df_base[df_base[\"editora\"] == edi][\"pop_editora\"].mean(),\n",
    "            \"pop_genero\": df_base[df_base[\"genero\"] == gen][\"pop_genero\"].mean(),\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "previsao = pipeline.predict(novo_livro)[0]\n",
    "print(f\"üìò Previs√£o de vendas do novo livro: {previsao:.0f} c√≥pias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé 3. Avalia√ß√£o local (confiabilidade por previs√£o)\n",
    "# Para medir o quanto o modelo est√° confiante em uma previs√£o espec√≠fica, h√° v√°rias estrat√©gias complementares:\n",
    "# a) Desvio entre previs√µes de √°rvores (XGBoost)\n",
    "# O XGBoost permite estimar a variabilidade entre √°rvores ‚Äî se as √°rvores divergem muito, a incerteza √© alta.\n",
    "\n",
    "# N√∫mero de √°rvores\n",
    "ntree = model.n_estimators\n",
    "\n",
    "# Obter predi√ß√µes de cada √°rvore individual\n",
    "predicoes_por_arvore = np.array(\n",
    "    [\n",
    "        model.predict(pipeline.named_steps[\"preprocessor\"].transform(novo_livro), iteration_range=(i, i + 1))\n",
    "        for i in range(ntree)\n",
    "    ]\n",
    ").flatten()\n",
    "\n",
    "media = predicoes_por_arvore.mean()\n",
    "desvio = predicoes_por_arvore.std()\n",
    "\n",
    "print(f\"Previs√£o m√©dia: {media:.0f}\")\n",
    "print(f\"Desvio entre √°rvores: {desvio:.1f}\")\n",
    "\n",
    "if desvio / media < 0.1:\n",
    "    print(\"‚úÖ Alta confian√ßa na previs√£o\")\n",
    "elif desvio / media < 0.25:\n",
    "    print(\"‚ö†Ô∏è Confian√ßa moderada\")\n",
    "else:\n",
    "    print(\"‚ùå Baixa confian√ßa ‚Äî resultado incerto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Dist√¢ncia do novo caso em rela√ß√£o aos dados de treino\n",
    "# Verifique se o novo livro √© similar aos exemplos que o modelo viu:\n",
    "\n",
    "# Extrair vetores de features (j√° processadas)\n",
    "X_train_transf = pipeline.named_steps[\"preprocessor\"].transform(X_train)\n",
    "novo_transf = pipeline.named_steps[\"preprocessor\"].transform(novo_livro)\n",
    "\n",
    "# Calcular dist√¢ncia m√©dia ao conjunto de treino\n",
    "distancias = cosine_distances(novo_transf, X_train_transf)\n",
    "distancia_min = np.min(distancias)\n",
    "\n",
    "print(f\"Dist√¢ncia m√≠nima ao conjunto de treino: {distancia_min:.3f}\")\n",
    "\n",
    "if distancia_min < 0.1:\n",
    "    print(\"‚úÖ Novo livro √© similar a casos conhecidos ‚Äî previs√£o confi√°vel\")\n",
    "elif distancia_min < 0.3:\n",
    "    print(\"‚ö†Ô∏è Novo livro √© parcialmente similar ‚Äî previs√£o moderadamente confi√°vel\")\n",
    "else:\n",
    "    print(\"‚ùå Novo livro muito diferente ‚Äî previs√£o incerta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae33d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Visualiza√ß√£o: previs√µes vs. reais\n",
    "# Um gr√°fico r√°pido para inspecionar se o modelo √© consistente:\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.xlabel(\"Vendas reais\")\n",
    "plt.ylabel(\"Vendas previstas\")\n",
    "plt.title(\"Acur√°cia das previs√µes por autor/livraria\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© 4. Dica pr√°tica: criar uma ‚Äúfaixa de previs√£o‚Äù\n",
    "# Voc√™ pode combinar a m√©dia e o desvio entre √°rvores para dar uma faixa de confian√ßa, por exemplo:\n",
    "ic_inferior = media - 1.96 * desvio\n",
    "ic_superior = media + 1.96 * desvio\n",
    "\n",
    "print(f\"Intervalo de confian√ßa 95%: {ic_inferior:.0f} a {ic_superior:.0f} c√≥pias\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
